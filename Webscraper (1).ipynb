{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5zgHsXmLPkA",
        "outputId": "9fc75fd6-89ad-4281-b887-aef5858cf149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.32.3)\n",
            "Collecting pyquery (from requests-html)\n",
            "  Downloading pyquery-2.0.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting fake-useragent (from requests-html)\n",
            "  Downloading fake_useragent-2.0.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting parse (from requests-html)\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting bs4 (from requests-html)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Collecting w3lib (from requests-html)\n",
            "  Downloading w3lib-2.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pyppeteer>=0.0.14 (from requests-html)\n",
            "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting appdirs<2.0.0,>=1.4.3 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (2025.1.31)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (8.6.1)\n",
            "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading pyee-11.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.67.1)\n",
            "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4->requests-html) (4.13.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyquery->requests-html) (5.3.1)\n",
            "Collecting cssselect>=1.2.0 (from pyquery->requests-html)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->requests-html) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->requests-html) (3.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4->requests-html) (2.6)\n",
            "Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading fake_useragent-2.0.3-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading pyquery-2.0.1-py3-none-any.whl (22 kB)\n",
            "Downloading w3lib-2.3.1-py3-none-any.whl (21 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading pyee-11.1.1-py3-none-any.whl (15 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: parse, appdirs, websockets, w3lib, urllib3, pyee, fake-useragent, cssselect, pyquery, pyppeteer, bs4, requests-html\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 14.2\n",
            "    Uninstalling websockets-14.2:\n",
            "      Successfully uninstalled websockets-14.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.2.0 requires websockets<15.0dev,>=13.0, but you have websockets 10.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 bs4-0.0.2 cssselect-1.2.0 fake-useragent-2.0.3 parse-1.20.2 pyee-11.1.1 pyppeteer-2.0.0 pyquery-2.0.1 requests-html-0.10.0 urllib3-1.26.20 w3lib-2.3.1 websockets-10.4\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests-html\n",
        "!pip install requests beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import textwrap\n",
        "\n",
        "url = \"https://economictimes.indiatimes.com/news/international/us/nvidia-stock-down-by-27-from-its-peak-heres-what-to-expect-next/articleshow/118788653.cms\"\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Try multiple possible selectors for article content\n",
        "    article_content = soup.select('.artText')\n",
        "\n",
        "    if not article_content:\n",
        "        article_content = soup.select('.normal')\n",
        "\n",
        "    if not article_content:\n",
        "        article_container = soup.select_one('.artText, .article-content, .article_content, .story-content')\n",
        "        if article_container:\n",
        "            article_content = article_container.find_all('p')\n",
        "\n",
        "    if not article_content:\n",
        "        article_content = soup.select('div.article p')\n",
        "\n",
        "    if article_content:\n",
        "        print(\"\\n=== ARTICLE CONTENT ===\\n\")\n",
        "\n",
        "        # Print title if available\n",
        "        title = soup.find('h1')\n",
        "        if title:\n",
        "            title_text = title.get_text(strip=True)\n",
        "            print(\"TITLE:\")\n",
        "            # Wrap title text at 80 characters\n",
        "            for line in textwrap.wrap(title_text, width=80):\n",
        "                print(line)\n",
        "            print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
        "\n",
        "        # Extract and print each paragraph with line wrapping\n",
        "        for i, para in enumerate(article_content, 1):\n",
        "            text = para.get_text(strip=True)\n",
        "            if text:  # Only print non-empty paragraphs\n",
        "                print(f\"PARAGRAPH {i}:\")\n",
        "\n",
        "                # Wrap text at 80 characters and indent subsequent lines\n",
        "                wrapped_lines = textwrap.wrap(text, width=80,\n",
        "                                             subsequent_indent='    ')\n",
        "\n",
        "                # Print each wrapped line\n",
        "                for line in wrapped_lines:\n",
        "                    print(line)\n",
        "\n",
        "                print(\"\\n\" + \"-\" * 80 + \"\\n\")  # Separator between paragraphs\n",
        "\n",
        "        print(\"=== END OF ARTICLE ===\")\n",
        "    else:\n",
        "        print(\"Article content not found. The website structure might have changed.\")\n",
        "        title = soup.title.string if soup.title else \"No title found\"\n",
        "        print(f\"Page title: {title}\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgfQyCW1Lq9b",
        "outputId": "e1893cc0-de04-46a1-97ad-11c8135b879a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ARTICLE CONTENT ===\n",
            "\n",
            "TITLE:\n",
            "Nvidia stock down by 27% from its peak, here's what to expect next\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "PARAGRAPH 1:\n",
            "Nvidia stock did not perform well in recent weeks, with its share prices trading\n",
            "    down nearly 16 percent year to date. Last week, the stock witnessed a 8\n",
            "    percent decline in a single day (Thursday), despite its earnings report\n",
            "    beating the estimates.During the fourth quarter, Nvidia registered 78\n",
            "    percent revenue growth to $39.3 billion, going beyond the predictions of\n",
            "    $38.2 billion. The AI chip leader's adjusted earnings per share (EPS) went\n",
            "    up from $0.49 to $0.89, while the estimates were at $0.85.Since the\n",
            "    beginning of 2023, Nvidia's stock has seen 600 percent jump in the market,\n",
            "    while its market currently hovers around $3 trillion.Why is Nvidia’s stock\n",
            "    down?According to financial services company The Motley Fool, the stock\n",
            "    price has been witnessing a downtrend as it gets caught up amid growing\n",
            "    concerns over US President Donald Trump's latest tariffs, accompanied by\n",
            "    concerns that its chips might have been illegally exported to\n",
            "    China.Currently, the Nvidia stock is down by 27 percent from its peak months\n",
            "    ago. This is the lowest it has been since September last year.Artificial\n",
            "    Intelligence(AI)Java Programming with ChatGPT: Learn using Generative AIBy -\n",
            "    Metla Sudha Sekhar, IT Specialist and DeveloperView ProgramArtificial\n",
            "    Intelligence(AI)Basics of Generative AI: Unveiling Tomorrows InnovationsBy -\n",
            "    Metla Sudha Sekhar, IT Specialist and DeveloperView ProgramArtificial\n",
            "    Intelligence(AI)Generative AI for Dynamic Java Web Applications with\n",
            "    ChatGPTBy - Metla Sudha Sekhar, IT Specialist and DeveloperView\n",
            "    ProgramMarketingPerformance Marketing for eCommerce BrandsBy - Zafer Mukeri,\n",
            "    Founder- Inara MarketersView ProgramArtificial Intelligence(AI)Mastering C++\n",
            "    Fundamentals with Generative AI: A Hands-OnBy - Metla Sudha Sekhar, IT\n",
            "    Specialist and DeveloperView ProgramFinanceA2Z Of MoneyBy - elearnmarkets,\n",
            "    Financial Education by StockEdgeView ProgramArtificial\n",
            "    Intelligence(AI)Master in Python Language Quickly Using the ChatGPT Open\n",
            "    AIBy - Metla Sudha Sekhar, IT Specialist and DeveloperView ProgramOffice\n",
            "    ProductivityZero to Hero in Microsoft Excel: Complete Excel guide 2024By -\n",
            "    Metla Sudha Sekhar, IT Specialist and DeveloperView ProgramArtificial\n",
            "    Intelligence(AI)AI and Analytics based Business StrategyBy - Tanusree De,\n",
            "    Managing Director- Accenture Technology Lead, Trustworthy AI Center of\n",
            "    Excellence: ATCIView ProgramTechnologyCertified Jenkins ProfessionalBy -\n",
            "    Vskills, India's Leading Certification BodyView ProgramAstrologyVastu\n",
            "    Shastra CourseBy - Sachenkumar Rai, Vastu ShashtriView ProgramData\n",
            "    ScienceSQL for Data Science along with Data Analytics and Data\n",
            "    VisualizationBy - Metla Sudha Sekhar, IT Specialist and DeveloperView\n",
            "    ProgramWeb DevelopmentA Comprehensive ASP.NET Core MVC 6 Project Guide for\n",
            "    2024By - Metla Sudha Sekhar, IT Specialist and DeveloperView ProgramOffice\n",
            "    ProductivityMastering Microsoft Office: Word, Excel, PowerPoint, and 365By -\n",
            "    Metla Sudha Sekhar, IT Specialist and DeveloperView ProgramMarketingDigital\n",
            "    marketing - Wordpress Website DevelopmentBy - Shraddha Somani, Digital\n",
            "    Marketing Trainer, Consultant, Strategiest and Subject Matter expertView\n",
            "    ProgramWeb DevelopmentMastering Full Stack Development: From Frontend to\n",
            "    Backend ExcellenceBy - Metla Sudha Sekhar, IT Specialist and DeveloperView\n",
            "    ProgramFinanceFinancial Literacy i.e Lets Crack the Billionaire CodeBy - CA\n",
            "    Rahul Gupta, CA with 10+ years of experience and Accounting EducatorView\n",
            "    ProgramLeadershipBusiness Storytelling MasterclassBy - Ameen Haque, Founder\n",
            "    of StorywallahsView ProgramMarketingFuture of Marketing & Branding\n",
            "    MasterclassBy - Dr. David Aaker, Professor Emeritus at the Haas School of\n",
            "    Business, UC Berkeley, Author | Speaker | Thought Leader | Branding\n",
            "    ConsultantView ProgramStrategyESG and Business Sustainability StrategyBy -\n",
            "    Vipul Arora, Partner, ESG & Climate Solutions at Sattva Consulting Author I\n",
            "    Speaker I Thought LeaderView ProgramIn the semiconductor sector, Nvidia has\n",
            "    seen only one other occasion during the past two years when it came down as\n",
            "    it has now.The last time it was pulled back so far was in July 2024. The\n",
            "    sell-off was due to fears over slowing down of investment in AI\n",
            "    infrastructure with concerns mounting about big companies overspending on\n",
            "    data centres as well as Nvidia chips, despite no meaningful returns.Also\n",
            "    Read :Jennifer Lopez upset over Ben Affleck’s growing closeness with\n",
            "    Jennifer Garner? Here’s the truthAfter experiencing a double dip, Nvidia was\n",
            "    back on track and reached its all -time highs in October last year.History\n",
            "    of NvidiaThe Motley Fool states Nvidia's share saw drawdowns of 50 percent\n",
            "    and above twice during the last 10 years.In 2018, the stock came down after\n",
            "    going up for about a year over concerns about rising interest rates and\n",
            "    tensions with China. Also, at that time there was a downtrend in the global\n",
            "    economy, which includes less demand for semiconductors as well.In a similar\n",
            "    fashion, the Nvidia stock witnessed another decline in 2022 as there was a\n",
            "    major crash in tech sector stocks after the revenue from crypto-related\n",
            "    demand came down.What's next for Nvidia?As of now, it is impossible to\n",
            "    predict how long Nvidia stock will see a downtrend or how far it will\n",
            "    fall.However, the financial services firm highlighted that the demand for\n",
            "    the company's all-new Blackwell chips is continuing to outrun supply.At the\n",
            "    same time, its \"competitive advantage in the data center graphics processing\n",
            "    units (GPUs) that make up the backbone of AI applications only seems to be\n",
            "    getting stronger,\" the report added.Nvidia is next expected to recoup its\n",
            "    recent losses in the market at some point of time in future.Also Read :Mindy\n",
            "    Kaling has this to say over Meghan Markle correcting her in Netflix\n",
            "    showFAQs1. What's the current price of Nvidia stock?According to the NASDAQ\n",
            "    website, Nvidia was trading at $111.44 at 7:59 AM ET on March 7.2. What past\n",
            "    shows about Nvidia's downtrend in stock market?History of the company's\n",
            "    share shows that sell-offs have been good buying opportunities for the\n",
            "    investors.(You can now subscribe to ourEconomic Times WhatsApp channel)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "PARAGRAPH 2:\n",
            "(You can now subscribe to ourEconomic Times WhatsApp channel)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== END OF ARTICLE ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dXA09rO1LuU0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HkwyIwza3F8U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qG3aRXpijz0r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qUQRtkfxkBbq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}